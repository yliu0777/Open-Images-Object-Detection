{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on Open-Images-2019-Object-Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "#### Google research launched the competion Open Images 2019 Object Detection on Kaggle on 06/03/2019 following its previous pair of competitions hosted in 2018. This competition built an ideal platform for people interested in ML/DL/CV to get some good insights into the latest technologies used in relative academic/industrial fields and offered a great opportunity to play with real-world large-scale image dataset. <br><br>This public notebook & repository is to collect and summarize relative online public notes/code implementations/research papers as well as my personal ipython notebook and results for the purpose of recording, sharing as well as self-monitoring. Any questions, suggestions or supplementations are welcomed!\n",
    "2019 competition link: https://www.kaggle.com/c/open-images-2019-object-detection/overview/description \n",
    "<br>sibling competition link: https://www.kaggle.com/c/open-images-2019-visual-relationship\n",
    "<br>Data source link: https://github.com/cvdfoundation/open-images-dataset#download-images-with-bounding-boxes-annotations\n",
    "<br>2018 competition link: https://www.kaggle.com/c/google-ai-open-images-object-detection-track\n",
    "<br>2018 sibling competition link: https://www.kaggle.com/c/google-ai-open-images-visual-relationship-track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ImageAI Framework\n",
    "kaggle link: https://www.kaggle.com/shivamb/objects-bounding-boxes-using-resnet50-imageai\n",
    "<br> ImageAI: https://github.com/OlafenwaMoses/ImageAI\n",
    "<br>\n",
    "<br> supported object names list: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus',\n",
    "                                 6: 'train',\n",
    "                                 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign',\n",
    "                                 12: 'parking meter',\n",
    "                                 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow',\n",
    "                                 20: 'elephant',\n",
    "                                 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag',\n",
    "                                 27: 'tie',\n",
    "                                 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball',\n",
    "                                 33: 'kite',\n",
    "                                 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard',\n",
    "                                 38: 'tennis racket',\n",
    "                                 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon',\n",
    "                                 45: 'bowl',\n",
    "                                 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot',\n",
    "                                 52: 'hot dog',\n",
    "                                 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant',\n",
    "                                 59: 'bed',\n",
    "                                 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote',\n",
    "                                 66: 'keyboard',\n",
    "                                 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink',\n",
    "                                 72: 'refrigerator',\n",
    "                                 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear',\n",
    "                                 78: 'hair dryer',\n",
    "                                 79: 'toothbrush'}\n",
    "<br>\n",
    "<br> Size of objects list in this competition is 600. Thus customized training is defnitely needed.\n",
    "<br> However, according to the document \n",
    "<br> https://github.com/OlafenwaMoses/ImageAI/blob/master/imageai/Detection/README.md#customdetection\n",
    "<br> Fine tuning with customized object list seems not be supported yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMDection\n",
    "https://github.com/open-mmlab/mmdetection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2018_2nd_place_solution_paper(512 gpus) : https://arxiv.org/pdf/1809.00778.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Utils Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_annotation_mapping():\n",
    "    \"\"\"\n",
    "    Read the object list to be supported for this competition. Return two dictionaries mapping \n",
    "    object_name into object_annotation and vice versa\n",
    "    \"\"\"\n",
    "    name_annotation_map = dict()\n",
    "    annotation_name_map = dict()\n",
    "    with open('../input/open-images-2019-object-detection/class-descriptions-boxable.csv', 'r', \n",
    "              encoding = 'utf-8-sig') as csvfile:\n",
    "        recs_table = csv.reader(csvfile, delimiter=',')\n",
    "        for row in recs_table:\n",
    "            annotation, name = row\n",
    "            name = name.lower()\n",
    "            name_annotation_map[name] = annotation\n",
    "            annotation_name_map[annotation] = name\n",
    "    return name_annotation_map, annotation_name_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
